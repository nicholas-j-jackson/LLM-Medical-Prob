# LLM Model Annotation Tool

This project is a web-based annotation tool that allows human annotators to label the use of probability statements in responses generated by LLMs. The application displays a textual response from a LLM and annotators label each statement as either having or not having a probability within it.

## Installation
1. Install the required dependencies:   ```pip install flask pillow```

## Usage
1. Start the Flask application:```python app.py```

2. Open your browser and go to http://127.0.0.1:5000/.

3. You will be presented with a LLM statement whether a probability is present in the response and if so enter the probabilities in the text boxes, then click "Submit and Next" to save your response to annotations.csv and proceed to the next image.

Navigate through the dataset using "Previous" and "Next" buttons.


## How It Works
- Flask Web Application: The application is powered by Flask, a lightweight web framework.
- Data Handling: Each JSON file contains text claims and labels. The app reads the claims from the JSON, presents them to the annotator, and stores the labels as either 1 (correct) or 0 (not correct) in the claim_labels array.
- Automatic Navigation: After each submission, the app automatically loads the next image-claim pair for labeling.